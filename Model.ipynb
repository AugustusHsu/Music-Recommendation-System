{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "Num_of_Unique_Song=130009\n",
    "Num_of_Unique_Tag=16141\n",
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457051, 6)\n",
      "(457051, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "idx_Song = np.load(data_dir + 'idx_Song.npy')\n",
    "idx_Tag = np.load(data_dir + 'idx_Tag.npy')\n",
    "print(idx_Song.shape)\n",
    "print(idx_Tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  864,  7109,  3440,  7110,  7111,  7112],\n",
       "       [ 7112,   864,  7109,  3440,  7110,  7112],\n",
       "       [  864,  7109,  3440,  7110,  7112, 21852],\n",
       "       [ 7109,  3440,  7110,  7112, 21852,   345],\n",
       "       [ 3440,  7110,  7112, 21852,   345,   346],\n",
       "       [ 7110,  7112, 21852,   345,   346,   347],\n",
       "       [ 7112, 21852,   345,   346,   347,   348],\n",
       "       [21852,   345,   346,   347,   348,   349],\n",
       "       [  345,   346,   347,   348,   349,   350],\n",
       "       [  346,   347,   348,   349,   350,   351]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_Song[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n",
      "(1000, 1)\n",
      "(1000, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "Song_X = idx_Song[:1000,0:5]\n",
    "print(Song_X.shape)\n",
    "Song_Y = idx_Song[:1000,5:6]\n",
    "print(Song_Y.shape)\n",
    "Tag_X = idx_Tag[:1000,0:5,:]\n",
    "print(Tag_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "Fake_Song = []\n",
    "#sample one hot data\n",
    "for _ in range(100):\n",
    "    Fake_Song.append([])\n",
    "    for _ in range(5):\n",
    "        random = np.random.randint(Num_of_Unique_Song)\n",
    "        #print(random)\n",
    "        Fake_Song[len(Fake_Song)-1].append(random)\n",
    "Fake_Song = np.array(Fake_Song)\n",
    "print(Fake_Song.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "Fake_Tag = []\n",
    "#sample one hot data\n",
    "for _ in range(100):\n",
    "    Fake_Tag.append([])\n",
    "    for _ in range(5):\n",
    "        Fake_Tag[len(Fake_Tag)-1].append([])\n",
    "        for _ in range(3):\n",
    "            random = np.random.randint(Num_of_Unique_Tag)\n",
    "            #print(random)\n",
    "            Fake_Tag[len(Fake_Tag)-1][len(Fake_Tag[len(Fake_Tag)-1])-1].append(random)\n",
    "Fake_Tag = np.array(Fake_Tag)\n",
    "print(Fake_Tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "Fake_Y = []\n",
    "#sample one hot data\n",
    "for _ in range(100):\n",
    "    Fake_Y.append([])\n",
    "    for _ in range(1):\n",
    "        random = np.random.randint(Num_of_Unique_Song)\n",
    "        #print(random)\n",
    "        Fake_Y[len(Fake_Y)-1].append(random)\n",
    "Fake_Y = np.array(Fake_Y)\n",
    "print(Fake_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song_Model:\n",
    "    def __init__(self):\n",
    "        # Data Size\n",
    "        self.song_size = 130009\n",
    "        self.num_song = 5\n",
    "        # Data\n",
    "        self.input_x = tf.placeholder(tf.int32, shape=[None, self.num_song], name='input_x')\n",
    "        # embedding output length\n",
    "        self.song_embedding_len = 50\n",
    "        # GRU setting\n",
    "        self.gru_neuron = 50\n",
    "        self.gru_size = 1\n",
    "        self.sequence_length = [5]\n",
    "        # Attention setting\n",
    "        self.attention_size = 1\n",
    "        # Drop out\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='song_keep_prob')\n",
    "        \n",
    "        # Song one hot layer\n",
    "        with tf.variable_scope('SONG_ONE_HOT'):\n",
    "            onehot_input = tf.one_hot(self.input_x, self.song_size, name='song_one_hot')\n",
    "            onehot_input = tf.reshape(onehot_input, [self.num_song, self.song_size])\n",
    "        print('onehot_input')\n",
    "        print(onehot_input.shape)\n",
    "            \n",
    "        # Song embedding layer\n",
    "        with tf.variable_scope('SONG_EMBEDDING'):\n",
    "            self.embedding = tf.Variable(tf.truncated_normal([self.song_size, self.song_embedding_len], stddev=0.1), \n",
    "                                         name='song_embedding_weight')\n",
    "            embedding_song = []\n",
    "            for s in range(self.num_song):\n",
    "                embedding_outputs = tf.reshape(tf.matmul(onehot_input[s:s+1, :], self.embedding), \n",
    "                                           [1, 1, self.song_embedding_len])\n",
    "                embedding_song.append(embedding_outputs)\n",
    "            embedding_outputs = tf.concat(embedding_song,axis=1)\n",
    "        print('embedding_outputs')\n",
    "        print(embedding_outputs.shape)\n",
    "        \n",
    "        \n",
    "        # Bi-GRU\n",
    "        # Define Forward RNN Cell\n",
    "        with tf.variable_scope('SONG_GRU_FORWARD') as scope:\n",
    "            fw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            fw_rnn_cell = tf.contrib.rnn.DropoutWrapper(fw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        # Define Backward RNN Cell\n",
    "        with tf.variable_scope('SONG_GRU_BACKWARD') as scope:\n",
    "            bw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            bw_rnn_cell = tf.contrib.rnn.DropoutWrapper(bw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        with tf.variable_scope('SONG_Bi_GRU'):\n",
    "            # embedding_inputs shape: (batch_size, sequence_length, embedding_size)\n",
    "            # rnn_output, _ = tf.nn.dynamic_rnn(fw_rnn_cell, inputs=embedding_inputs, \n",
    "            #                                   sequence_length=self.seq_len, dtype=tf.float32)\n",
    "            rnn_output, _ = tf.nn.bidirectional_dynamic_rnn(fw_rnn_cell, bw_rnn_cell, \n",
    "                                                            inputs=embedding_outputs, \n",
    "                                                            sequence_length=self.sequence_length, \n",
    "                                                            dtype=tf.float32)\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs\n",
    "        if isinstance(rnn_output, tuple):\n",
    "            bigru_output = tf.concat(rnn_output, 2)\n",
    "        print('bigru_output')\n",
    "        print(bigru_output.shape)\n",
    "        \n",
    "        # Attention Layer\n",
    "        with tf.name_scope('SONG_ATTENTION'):\n",
    "            input_shape = bigru_output.shape # (batch_size, sequence_length, hidden_size)\n",
    "            sequence_size = input_shape[1].value  # the length of sequences processed in the RNN layer\n",
    "            hidden_size = input_shape[2].value  # hidden size of the RNN layer\n",
    "            #print(hidden_size)\n",
    "\n",
    "            attention_w = tf.Variable(tf.truncated_normal([hidden_size, self.attention_size], stddev=0.1), \n",
    "                                      name='song_attention_weight')\n",
    "            #attention_b = tf.Variable(tf.constant(0.1, shape=[attention_size]), name='attention_b')\n",
    "            #attention_u = tf.Variable(tf.truncated_normal([attention_size], stddev=0.1), name='attention_u')\n",
    "            z_list = []\n",
    "            for t in range(sequence_size):\n",
    "                u_t = tf.tanh(tf.matmul(bigru_output[:, t, :], attention_w))\n",
    "                #z_t = tf.matmul(u_t, tf.reshape(attention_u, [-1, 1]))\n",
    "                z_list.append(u_t)\n",
    "            # Transform to batch_size * sequence_size\n",
    "            self.attention_output = tf.concat(z_list, axis=1)\n",
    "            #self.alpha = tf.nn.softmax(attention_z)\n",
    "            # Transform to batch_size * sequence_size * 1 , same rank as bigru_output\n",
    "            #self.attention_output = tf.reduce_sum(bigru_output * tf.reshape(self.attention_z, \n",
    "            #                                                                [-1, sequence_size, 1]), 1)\n",
    "        print('attention_output')\n",
    "        print(self.attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag_Model:\n",
    "    def __init__(self):\n",
    "        # Data Size\n",
    "        self.tag_size = 16141\n",
    "        self.num_song = 5\n",
    "        self.num_tag = 3\n",
    "        # Data\n",
    "        self.input_x = tf.placeholder(tf.int32, shape=[None, self.num_song, self.num_tag], name='input_x')\n",
    "        # Embedding setting\n",
    "        self.num_tag_list = [3,2,1,1,2]\n",
    "        self.tag_embedding_len = 25\n",
    "        # GRU setting\n",
    "        self.gru_neuron = 50\n",
    "        self.gru_size = 5\n",
    "        self.sequence_length = [5]\n",
    "        # Attention setting\n",
    "        self.attention_size = 1\n",
    "        \n",
    "        # Drop out\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='tag_keep_prob')\n",
    "        #learning rate\n",
    "        self.lr = 0.05\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        #self.g_params = []\n",
    "        \n",
    "        # Tag one hot layer\n",
    "        with tf.variable_scope('Tag_ONE_HOT'):\n",
    "            onehot_input = tf.one_hot(self.input_x, self.tag_size, name='tag_one_hot')\n",
    "            onehot_input = tf.reshape(onehot_input, [self.num_song, self.num_tag, self.tag_size])\n",
    "        print('onehot_input')\n",
    "        print(onehot_input.shape)\n",
    "        \n",
    "        #tag embedding layer\n",
    "        with tf.variable_scope('TAG_EMBEDDING'):\n",
    "            self.embedding = tf.Variable(tf.truncated_normal([self.tag_size, self.tag_embedding_len], stddev=0.1), \n",
    "                                         name='tag_embedding_weight')\n",
    "            embedding_tag = []\n",
    "            for s in range(self.num_song):\n",
    "                for num in self.num_tag_list:\n",
    "                    sum_embedding_tag = []\n",
    "                    for t in range(num):\n",
    "                        tag_vector = tf.matmul(tf.reshape(onehot_input[s:s+1,t:t+1,:],[1, self.tag_size]), \n",
    "                                                  self.embedding)\n",
    "                        sum_embedding_tag.append(tag_vector)\n",
    "                embedding_tag.append(tf.reduce_mean(sum_embedding_tag, 0))\n",
    "            embedding_outputs = tf.concat(embedding_tag,axis=0)\n",
    "            embedding_outputs = tf.reshape(embedding_outputs, [1, self.num_song, self.tag_embedding_len])\n",
    "        print('embedding_outputs')\n",
    "        print(embedding_outputs.shape)\n",
    "        \n",
    "        #Bi-GRU\n",
    "        # Define Forward RNN Cell\n",
    "        with tf.variable_scope('TAG_GRU_FORWARD') as scope:\n",
    "            fw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            fw_rnn_cell = tf.contrib.rnn.DropoutWrapper(fw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        # Define Backward RNN Cell\n",
    "        with tf.variable_scope('TAG_GRU_BACKWARD') as scope:\n",
    "            bw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            bw_rnn_cell = tf.contrib.rnn.DropoutWrapper(bw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        with tf.variable_scope('TAG_Bi_GRU'):\n",
    "            # embedding_inputs shape: (batch_size, sequence_length, embedding_size)\n",
    "            # rnn_output, _ = tf.nn.dynamic_rnn(fw_rnn_cell, inputs=embedding_inputs, \n",
    "            #                                   sequence_length=self.seq_len, dtype=tf.float32)\n",
    "            rnn_output, _ = tf.nn.bidirectional_dynamic_rnn(fw_rnn_cell, bw_rnn_cell, \n",
    "                                                            inputs=embedding_outputs, \n",
    "                                                            sequence_length=self.sequence_length, \n",
    "                                                            dtype=tf.float32)\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs\n",
    "        if isinstance(rnn_output, tuple):\n",
    "            bigru_output = tf.concat(rnn_output, 2)\n",
    "        print('bigru_output')\n",
    "        print(bigru_output.shape)\n",
    "        \n",
    "        # Attention Layer\n",
    "        with tf.name_scope('TAG_ATTENTION'):\n",
    "            input_shape = bigru_output.shape # (batch_size, sequence_length, hidden_size)\n",
    "            sequence_size = input_shape[1].value  # the length of sequences processed in the RNN layer\n",
    "            hidden_size = input_shape[2].value  # hidden size of the RNN layer\n",
    "            #print(hidden_size)\n",
    "\n",
    "            attention_w = tf.Variable(tf.truncated_normal([hidden_size, self.attention_size], stddev=0.1), \n",
    "                                      name='tag_attention_weight')\n",
    "            #attention_b = tf.Variable(tf.constant(0.1, shape=[attention_size]), name='attention_b')\n",
    "            #attention_u = tf.Variable(tf.truncated_normal([attention_size], stddev=0.1), name='attention_u')\n",
    "            z_list = []\n",
    "            for t in range(sequence_size):\n",
    "                u_t = tf.tanh(tf.matmul(bigru_output[:, t, :], attention_w))\n",
    "                #z_t = tf.matmul(u_t, tf.reshape(attention_u, [-1, 1]))\n",
    "                z_list.append(u_t)\n",
    "            # Transform to batch_size * sequence_size\n",
    "            self.attention_output = tf.concat(z_list, axis=1)\n",
    "            #self.alpha = tf.nn.softmax(attention_z)\n",
    "            # Transform to batch_size * sequence_size * 1 , same rank as bigru_output\n",
    "            #self.attention_output = tf.reduce_sum(bigru_output * tf.reshape(self.attention_z, [-1, sequence_size, 1]), 1)\n",
    "        print('attention_output')\n",
    "        print(self.attention_output.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALL_Model:\n",
    "    def __init__(self):\n",
    "        self.Song_Part = Song_Model()\n",
    "        self.Tag_Part = Tag_Model()\n",
    "        self.FC_input = tf.concat(axis=1, values=[self.Song_Part.attention_output, \n",
    "                                                  self.Tag_Part.attention_output])\n",
    "        #self.FC_input = self.Song_Part.attention_output\n",
    "        print('FC_input')\n",
    "        print( self.FC_input.shape)\n",
    "        \n",
    "        # fully connected setting\n",
    "        self.fully_input_d = self.FC_input.get_shape().as_list()[1]\n",
    "        self.fully_neuron = 50\n",
    "        # output setting\n",
    "        self.outpu_d = 130009\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fully connected layer\n",
    "        with tf.name_scope('FULLY_CONNECTED_LAYER'):\n",
    "            fully_weight = tf.Variable(tf.truncated_normal([self.fully_input_d, self.fully_neuron], \n",
    "                                                           stddev=0.1), name='fully_weight')\n",
    "            fully_bais = tf.Variable(tf.constant(0.1, shape=[1, self.fully_neuron]), name='fully_bais')\n",
    "        FC_output = tf.nn.relu(tf.matmul(self.FC_input, fully_weight) + fully_bais)\n",
    "        print('FC_output')\n",
    "        print(FC_output.shape)\n",
    "        \n",
    "        # Output layer\n",
    "        with tf.name_scope('OUTPUT_LAYER'):\n",
    "            fully_weight = tf.Variable(tf.truncated_normal([self.fully_neuron, self.outpu_d], \n",
    "                                                           stddev=0.1), name='Output_weight')\n",
    "            fully_bais = tf.Variable(tf.constant(0.1, shape=[1, self.outpu_d]), name='Output_bais')\n",
    "        self.Output = tf.matmul(FC_output, fully_weight) + fully_bais\n",
    "        print('Output')\n",
    "        print(self.Output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehot_input\n",
      "(5, 130009)\n",
      "embedding_outputs\n",
      "(1, 5, 50)\n",
      "bigru_output\n",
      "(1, 5, 2)\n",
      "attention_output\n",
      "(1, 5)\n",
      "onehot_input\n",
      "(5, 3, 16141)\n",
      "embedding_outputs\n",
      "(1, 5, 25)\n",
      "bigru_output\n",
      "(1, 5, 10)\n",
      "attention_output\n",
      "(1, 5)\n",
      "FC_input\n",
      "(1, 10)\n",
      "FC_output\n",
      "(1, 50)\n",
      "Output\n",
      "(1, 130009)\n",
      "onehot_label\n",
      "(1, 130009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:54<00:00,  3.01it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:\n",
      "train loss: 11.84806632995605468750, train accuracy: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:49<00:00,  3.03it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1:\n",
      "train loss: 10.13523197174072265625, train accuracy: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 683/1000 [04:02<01:49,  2.89it/s]"
     ]
    }
   ],
   "source": [
    "Model = tf.Graph()\n",
    "tf.reset_default_graph()\n",
    "with Model.as_default():\n",
    "    tf_config = tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=False)\n",
    "    #tf_config.per_process_gpu_memory_fraction = 0.8\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tf_config).as_default() as sess:\n",
    "        model = ALL_Model()\n",
    "        learning_rate = 0.005\n",
    "        grad_clip = 5.0\n",
    "        num_predict = 1\n",
    "        Num_of_Unique_Song=130009\n",
    "        Num_of_Unique_Tag=16141\n",
    "        input_y = tf.placeholder(tf.int32, shape=[None, num_predict], name='input_y')\n",
    "        # Label one hot layer\n",
    "        with tf.variable_scope('LABEL_ONE_HOT'):\n",
    "            onehot_label = tf.one_hot(input_y, Num_of_Unique_Song, name='label_one_hot')\n",
    "            onehot_label = tf.reshape(onehot_label, [num_predict, Num_of_Unique_Song])\n",
    "            print('onehot_label')\n",
    "            print(onehot_label.shape)\n",
    "        \n",
    "        # Calculate cross-entropy loss\n",
    "        with tf.name_scope('loss'):\n",
    "            log_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=model.Output, labels=onehot_label)\n",
    "            loss = tf.reduce_mean(log_loss)\n",
    "            \n",
    "        # Create optimizer\n",
    "        with tf.name_scope('optimization'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            \n",
    "            train_op = optimizer.minimize(loss)\n",
    "            \n",
    "            #gradients, variables = zip(*optimizer.compute_gradients(loss))\n",
    "            #gradients, _ = tf.clip_by_global_norm(gradients, grad_clip)\n",
    "            #train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        with tf.name_scope('accuracy'):\n",
    "            predictions = tf.argmax(model.Output, 1, name='predictions')\n",
    "            correct_pred = tf.equal(predictions, tf.argmax(onehot_label, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        \n",
    "        for epoch in range(5):\n",
    "            #random\n",
    "            random_size = 1\n",
    "            for i in tqdm.tqdm(range(Song_X.shape[0]//random_size)):\n",
    "                if random_size == 1:\n",
    "                    start = i\n",
    "                    end = i + 1\n",
    "                else:\n",
    "                    idx = np.random.randint(Song_X.shape[0]) - 1\n",
    "                    start = min(idx, Song_X.shape[0] - 1)\n",
    "                    end = min(idx + 1, Song_X.shape[0])\n",
    "\n",
    "                Song_input = Song_X[start:end,:]\n",
    "                Tag_input = Tag_X[start:end,:,:]\n",
    "                Song_label = Song_Y[start:end,:]\n",
    "                \n",
    "                feed_dict = {model.Song_Part.input_x: Song_input, \n",
    "                             model.Tag_Part.input_x: Tag_input, \n",
    "                             input_y: Song_label, \n",
    "                             model.Song_Part.keep_prob: 0.9, \n",
    "                             model.Tag_Part.keep_prob: 0.9\n",
    "                            }\n",
    "                _, train_loss, train_accuracy = sess.run([train_op, loss, accuracy], feed_dict=feed_dict)\n",
    "            print(\"Epoch: {}:\".format(epoch))\n",
    "            print(\"train loss: {:.20f}, train accuracy: {:.3f}\\n\".format(train_loss, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tf_config = tf.ConfigProto(\n",
    "        allow_soft_placemerelunt=True,FC_output\n",
    "        log_device_placement=False)\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tf_config).as_default() as sess:\n",
    "        rnn = Song_Model()\n",
    "        # Summaries for loss and accuracy\n",
    "        tf.summary.scalar(\"loss\", rnn.loss)\n",
    "        tf.summary.scalar(\"accuracy\", rnn.accuracy)\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
