{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "Num_of_Unique_Song=130009\n",
    "Num_of_Unique_Tag=16141\n",
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457051, 6)\n",
      "(457051, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "idx_Song = np.load(data_dir + 'idx_Song.npy')\n",
    "idx_Tag = np.load(data_dir + 'idx_Tag.npy')\n",
    "print(idx_Song.shape)\n",
    "print(idx_Tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 1)\n",
      "(100, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "Song_X = idx_Song[:100,0:5]\n",
    "print(Song_X.shape)\n",
    "Song_Y = idx_Song[:100,5:6]\n",
    "print(Song_Y.shape)\n",
    "Tag_X = idx_Tag[:100,0:5,:]\n",
    "print(Tag_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "Fake_Song = []\n",
    "#sample one hot data\n",
    "for _ in range(100):\n",
    "    Fake_Song.append([])\n",
    "    for _ in range(5):\n",
    "        random = np.random.randint(Num_of_Unique_Song)\n",
    "        #print(random)\n",
    "        Fake_Song[len(Fake_Song)-1].append(random)\n",
    "Fake_Song = np.array(Fake_Song)\n",
    "print(Fake_Song.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "Fake_Tag = []\n",
    "#sample one hot data\n",
    "for _ in range(100):\n",
    "    Fake_Tag.append([])\n",
    "    for _ in range(5):\n",
    "        Fake_Tag[len(Fake_Tag)-1].append([])\n",
    "        for _ in range(3):\n",
    "            random = np.random.randint(Num_of_Unique_Tag)\n",
    "            #print(random)\n",
    "            Fake_Tag[len(Fake_Tag)-1][len(Fake_Tag[len(Fake_Tag)-1])-1].append(random)\n",
    "Fake_Tag = np.array(Fake_Tag)\n",
    "print(Fake_Tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "Fake_Y = []\n",
    "#sample one hot data\n",
    "for _ in range(100):\n",
    "    Fake_Y.append([])\n",
    "    for _ in range(1):\n",
    "        random = np.random.randint(Num_of_Unique_Song)\n",
    "        #print(random)\n",
    "        Fake_Y[len(Fake_Y)-1].append(random)\n",
    "Fake_Y = np.array(Fake_Y)\n",
    "print(Fake_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song_Model:\n",
    "    def __init__(self):\n",
    "        # Data Size\n",
    "        self.song_size = 130009\n",
    "        self.num_song = 5\n",
    "        # Data\n",
    "        self.input_x = tf.placeholder(tf.int32, shape=[None, self.num_song], name='input_x')\n",
    "        # embedding output length\n",
    "        self.song_embedding_len = 50\n",
    "        # GRU setting\n",
    "        self.gru_neuron = 50\n",
    "        self.gru_size = 1\n",
    "        self.sequence_length = [5]\n",
    "        # Attention setting\n",
    "        self.attention_size = 1\n",
    "        # Drop out\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='song_keep_prob')\n",
    "        \n",
    "        # Song one hot layer\n",
    "        with tf.variable_scope('SONG_ONE_HOT'):\n",
    "            onehot_input = tf.one_hot(self.input_x, self.song_size, name='song_one_hot')\n",
    "            onehot_input = tf.reshape(onehot_input, [self.num_song, self.song_size])\n",
    "        print('onehot_input')\n",
    "        print(onehot_input.shape)\n",
    "            \n",
    "        # Song embedding layer\n",
    "        with tf.variable_scope('SONG_EMBEDDING'):\n",
    "            self.embedding = tf.Variable(tf.truncated_normal([self.song_size, self.song_embedding_len], stddev=0.1), \n",
    "                                         name='song_embedding_weight')\n",
    "            embedding_song = []\n",
    "            for s in range(self.num_song):\n",
    "                embedding_outputs = tf.reshape(tf.matmul(onehot_input[s:s+1, :], self.embedding), \n",
    "                                           [1, 1, self.song_embedding_len])\n",
    "                embedding_song.append(embedding_outputs)\n",
    "            embedding_outputs = tf.concat(embedding_song,axis=1)\n",
    "        print('embedding_outputs')\n",
    "        print(embedding_outputs.shape)\n",
    "        \n",
    "        \n",
    "        # Bi-GRU\n",
    "        # Define Forward RNN Cell\n",
    "        with tf.variable_scope('SONG_GRU_FORWARD') as scope:\n",
    "            fw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            fw_rnn_cell = tf.contrib.rnn.DropoutWrapper(fw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        # Define Backward RNN Cell\n",
    "        with tf.variable_scope('SONG_GRU_BACKWARD') as scope:\n",
    "            bw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            bw_rnn_cell = tf.contrib.rnn.DropoutWrapper(bw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        with tf.variable_scope('SONG_Bi_GRU'):\n",
    "            # embedding_inputs shape: (batch_size, sequence_length, embedding_size)\n",
    "            # rnn_output, _ = tf.nn.dynamic_rnn(fw_rnn_cell, inputs=embedding_inputs, \n",
    "            #                                   sequence_length=self.seq_len, dtype=tf.float32)\n",
    "            rnn_output, _ = tf.nn.bidirectional_dynamic_rnn(fw_rnn_cell, bw_rnn_cell, \n",
    "                                                            inputs=embedding_outputs, \n",
    "                                                            sequence_length=self.sequence_length, \n",
    "                                                            dtype=tf.float32)\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs\n",
    "        if isinstance(rnn_output, tuple):\n",
    "            bigru_output = tf.concat(rnn_output, 2)\n",
    "        print('bigru_output')\n",
    "        print(bigru_output.shape)\n",
    "        \n",
    "        # Attention Layer\n",
    "        with tf.name_scope('SONG_ATTENTION'):\n",
    "            input_shape = bigru_output.shape # (batch_size, sequence_length, hidden_size)\n",
    "            sequence_size = input_shape[1].value  # the length of sequences processed in the RNN layer\n",
    "            hidden_size = input_shape[2].value  # hidden size of the RNN layer\n",
    "            #print(hidden_size)\n",
    "\n",
    "            attention_w = tf.Variable(tf.truncated_normal([hidden_size, self.attention_size], stddev=0.1), \n",
    "                                      name='song_attention_weight')\n",
    "            #attention_b = tf.Variable(tf.constant(0.1, shape=[attention_size]), name='attention_b')\n",
    "            #attention_u = tf.Variable(tf.truncated_normal([attention_size], stddev=0.1), name='attention_u')\n",
    "            z_list = []\n",
    "            for t in range(sequence_size):\n",
    "                u_t = tf.tanh(tf.matmul(bigru_output[:, t, :], attention_w))\n",
    "                #z_t = tf.matmul(u_t, tf.reshape(attention_u, [-1, 1]))\n",
    "                z_list.append(u_t)\n",
    "            # Transform to batch_size * sequence_size\n",
    "            self.attention_output = tf.concat(z_list, axis=1)\n",
    "            #self.alpha = tf.nn.softmax(attention_z)\n",
    "            # Transform to batch_size * sequence_size * 1 , same rank as bigru_output\n",
    "            #self.attention_output = tf.reduce_sum(bigru_output * tf.reshape(self.attention_z, \n",
    "            #                                                                [-1, sequence_size, 1]), 1)\n",
    "        print('attention_output')\n",
    "        print(self.attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag_Model:\n",
    "    def __init__(self):\n",
    "        # Data Size\n",
    "        self.tag_size = 16141\n",
    "        self.num_song = 5\n",
    "        self.num_tag = 3\n",
    "        # Data\n",
    "        self.input_x = tf.placeholder(tf.int32, shape=[None, self.num_song, self.num_tag], name='input_x')\n",
    "        # Embedding setting\n",
    "        self.num_tag_list = [3,2,1,1,2]\n",
    "        self.tag_embedding_len = 25\n",
    "        # GRU setting\n",
    "        self.gru_neuron = 50\n",
    "        self.gru_size = 5\n",
    "        self.sequence_length = [5]\n",
    "        # Attention setting\n",
    "        self.attention_size = 1\n",
    "        \n",
    "        # Drop out\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='tag_keep_prob')\n",
    "        #learning rate\n",
    "        self.lr = 0.05\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        #self.g_params = []\n",
    "        \n",
    "        # Tag one hot layer\n",
    "        with tf.variable_scope('Tag_ONE_HOT'):\n",
    "            onehot_input = tf.one_hot(self.input_x, self.tag_size, name='tag_one_hot')\n",
    "            onehot_input = tf.reshape(onehot_input, [self.num_song, self.num_tag, self.tag_size])\n",
    "        print('onehot_input')\n",
    "        print(onehot_input.shape)\n",
    "        \n",
    "        #tag embedding layer\n",
    "        with tf.variable_scope('TAG_EMBEDDING'):\n",
    "            self.embedding = tf.Variable(tf.truncated_normal([self.tag_size, self.tag_embedding_len], stddev=0.1), \n",
    "                                         name='tag_embedding_weight')\n",
    "            embedding_tag = []\n",
    "            for s in range(self.num_song):\n",
    "                for num in self.num_tag_list:\n",
    "                    sum_embedding_tag = []\n",
    "                    for t in range(num):\n",
    "                        tag_vector = tf.matmul(tf.reshape(onehot_input[s:s+1,t:t+1,:],[1, self.tag_size]), \n",
    "                                                  self.embedding)\n",
    "                        sum_embedding_tag.append(tag_vector)\n",
    "                embedding_tag.append(tf.reduce_mean(sum_embedding_tag, 0))\n",
    "            embedding_outputs = tf.concat(embedding_tag,axis=0)\n",
    "            embedding_outputs = tf.reshape(embedding_outputs, [1, self.num_song, self.tag_embedding_len])\n",
    "        print('embedding_outputs')\n",
    "        print(embedding_outputs.shape)\n",
    "        \n",
    "        #Bi-GRU\n",
    "        # Define Forward RNN Cell\n",
    "        with tf.variable_scope('TAG_GRU_FORWARD') as scope:\n",
    "            fw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            fw_rnn_cell = tf.contrib.rnn.DropoutWrapper(fw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        # Define Backward RNN Cell\n",
    "        with tf.variable_scope('TAG_GRU_BACKWARD') as scope:\n",
    "            bw_rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(self.gru_size) \n",
    "                                                       for _ in range(self.gru_neuron)])\n",
    "            bw_rnn_cell = tf.contrib.rnn.DropoutWrapper(bw_rnn_cell, output_keep_prob=self.keep_prob)\n",
    "        \n",
    "        with tf.variable_scope('TAG_Bi_GRU'):\n",
    "            # embedding_inputs shape: (batch_size, sequence_length, embedding_size)\n",
    "            # rnn_output, _ = tf.nn.dynamic_rnn(fw_rnn_cell, inputs=embedding_inputs, \n",
    "            #                                   sequence_length=self.seq_len, dtype=tf.float32)\n",
    "            rnn_output, _ = tf.nn.bidirectional_dynamic_rnn(fw_rnn_cell, bw_rnn_cell, \n",
    "                                                            inputs=embedding_outputs, \n",
    "                                                            sequence_length=self.sequence_length, \n",
    "                                                            dtype=tf.float32)\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs\n",
    "        if isinstance(rnn_output, tuple):\n",
    "            bigru_output = tf.concat(rnn_output, 2)\n",
    "        print('bigru_output')\n",
    "        print(bigru_output.shape)\n",
    "        \n",
    "        # Attention Layer\n",
    "        with tf.name_scope('TAG_ATTENTION'):\n",
    "            input_shape = bigru_output.shape # (batch_size, sequence_length, hidden_size)\n",
    "            sequence_size = input_shape[1].value  # the length of sequences processed in the RNN layer\n",
    "            hidden_size = input_shape[2].value  # hidden size of the RNN layer\n",
    "            #print(hidden_size)\n",
    "\n",
    "            attention_w = tf.Variable(tf.truncated_normal([hidden_size, self.attention_size], stddev=0.1), \n",
    "                                      name='tag_attention_weight')\n",
    "            #attention_b = tf.Variable(tf.constant(0.1, shape=[attention_size]), name='attention_b')\n",
    "            #attention_u = tf.Variable(tf.truncated_normal([attention_size], stddev=0.1), name='attention_u')\n",
    "            z_list = []\n",
    "            for t in range(sequence_size):\n",
    "                u_t = tf.tanh(tf.matmul(bigru_output[:, t, :], attention_w))\n",
    "                #z_t = tf.matmul(u_t, tf.reshape(attention_u, [-1, 1]))\n",
    "                z_list.append(u_t)\n",
    "            # Transform to batch_size * sequence_size\n",
    "            self.attention_output = tf.concat(z_list, axis=1)\n",
    "            #self.alpha = tf.nn.softmax(attention_z)\n",
    "            # Transform to batch_size * sequence_size * 1 , same rank as bigru_output\n",
    "            #self.attention_output = tf.reduce_sum(bigru_output * tf.reshape(self.attention_z, [-1, sequence_size, 1]), 1)\n",
    "        print('attention_output')\n",
    "        print(self.attention_output.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALL_Model:\n",
    "    def __init__(self):\n",
    "        self.Song_Part = Song_Model()\n",
    "        self.Tag_Part = Tag_Model()\n",
    "        self.FC_input = tf.concat(axis=1, values=[self.Song_Part.attention_output, \n",
    "                                                  self.Tag_Part.attention_output])\n",
    "        #self.FC_input = self.Song_Part.attention_output\n",
    "        print('FC_input')\n",
    "        print( self.FC_input.shape)\n",
    "        \n",
    "        # fully connected setting\n",
    "        self.fully_input_d = self.FC_input.get_shape().as_list()[1]\n",
    "        self.fully_neuron = 50\n",
    "        # output setting\n",
    "        self.outpu_d = 130009\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fully connected layer\n",
    "        with tf.name_scope('FULLY_CONNECTED_LAYER'):\n",
    "            fully_weight = tf.Variable(tf.truncated_normal([self.fully_input_d, self.fully_neuron], \n",
    "                                                           stddev=0.1), name='fully_weight')\n",
    "            fully_bais = tf.Variable(tf.constant(0.1, shape=[1, self.fully_neuron]), name='fully_bais')\n",
    "        FC_output = tf.nn.relu(tf.matmul(self.FC_input, fully_weight) + fully_bais)\n",
    "        print('FC_output')\n",
    "        print(FC_output.shape)\n",
    "        \n",
    "        # Output layer\n",
    "        with tf.name_scope('OUTPUT_LAYER'):\n",
    "            fully_weight = tf.Variable(tf.truncated_normal([self.fully_neuron, self.outpu_d], \n",
    "                                                           stddev=0.1), name='Output_weight')\n",
    "            fully_bais = tf.Variable(tf.constant(0.1, shape=[1, self.outpu_d]), name='Output_bais')\n",
    "        self.Output = tf.nn.softmax(tf.matmul(FC_output, fully_weight) + fully_bais)\n",
    "        print('Output')\n",
    "        print(self.Output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehot_input\n",
      "(5, 130009)\n",
      "embedding_outputs\n",
      "(1, 5, 50)\n",
      "bigru_output\n",
      "(1, 5, 2)\n",
      "attention_output\n",
      "(1, 5)\n",
      "FC_input\n",
      "(1, 5)\n",
      "FC_output\n",
      "(1, 50)\n",
      "Output\n",
      "(1, 130009)\n",
      "onehot_label\n",
      "(1, 130009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  3.94it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:\n",
      "train loss: 11.77537155151367187500, train accuracy: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  4.05it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1:\n",
      "train loss: 11.77537155151367187500, train accuracy: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [00:23<00:02,  3.90it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dde58b3b8413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                              \u001b[0;31m#model.Tag_Part.keep_prob: 0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                             }\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train loss: {:.20f}, train accuracy: {:.3f}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Model = tf.Graph()\n",
    "tf.reset_default_graph()\n",
    "with Model.as_default():\n",
    "    tf_config = tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=False)\n",
    "    #tf_config.per_process_gpu_memory_fraction = 0.8\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tf_config).as_default() as sess:\n",
    "        model = ALL_Model()\n",
    "        learning_rate = 0.5\n",
    "        grad_clip = 5.0\n",
    "        num_predict = 1\n",
    "        Num_of_Unique_Song=130009\n",
    "        Num_of_Unique_Tag=16141\n",
    "        input_y = tf.placeholder(tf.int32, shape=[None, num_predict], name='input_y')\n",
    "        # Label one hot layer\n",
    "        with tf.variable_scope('LABEL_ONE_HOT'):\n",
    "            onehot_label = tf.one_hot(input_y, Num_of_Unique_Song, name='label_one_hot')\n",
    "            onehot_label = tf.reshape(onehot_label, [num_predict, Num_of_Unique_Song])\n",
    "            print('onehot_label')\n",
    "            print(onehot_label.shape)\n",
    "        \n",
    "        # Calculate cross-entropy loss\n",
    "        with tf.name_scope('loss'):\n",
    "            log_loss = tf.losses.softmax_cross_entropy(logits=model.Output, onehot_labels=onehot_label)\n",
    "            loss = tf.reduce_mean(log_loss)\n",
    "            \n",
    "        # Create optimizer\n",
    "        with tf.name_scope('optimization'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            \n",
    "            train_op = optimizer.minimize(loss)\n",
    "            \n",
    "            #gradients, variables = zip(*optimizer.compute_gradients(loss))\n",
    "            #gradients, _ = tf.clip_by_global_norm(gradients, grad_clip)\n",
    "            #train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        with tf.name_scope('accuracy'):\n",
    "            predictions = tf.argmax(model.Output, 1, name='predictions')\n",
    "            correct_pred = tf.equal(predictions, tf.argmax(onehot_label, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        \n",
    "        for epoch in range(5):\n",
    "            #random\n",
    "            random_size = 1\n",
    "            for i in tqdm.tqdm(range(Song_X.shape[0]//random_size)):\n",
    "                if random_size == 1:\n",
    "                    start = i\n",
    "                    end = i + 1\n",
    "                else:\n",
    "                    idx = np.random.randint(Song_X.shape[0]) - 1\n",
    "                    start = min(idx, Song_X.shape[0] - 1)\n",
    "                    end = min(idx + 1, Song_X.shape[0])\n",
    "\n",
    "                Song_input = Song_X[start:end,:]\n",
    "                Tag_input = Tag_X[start:end,:,:]\n",
    "                Song_label = Song_Y[start:end,:]\n",
    "                \n",
    "                feed_dict = {model.Song_Part.input_x: Song_input, \n",
    "                             #model.Tag_Part.input_x: Tag_input, \n",
    "                             input_y: Song_label, \n",
    "                             model.Song_Part.keep_prob: 0.9, \n",
    "                             #model.Tag_Part.keep_prob: 0.9\n",
    "                            }\n",
    "                _, train_loss, train_accuracy = sess.run([train_op, loss, accuracy], feed_dict=feed_dict)\n",
    "            print(\"Epoch: {}:\".format(epoch))\n",
    "            print(\"train loss: {:.20f}, train accuracy: {:.3f}\\n\".format(train_loss, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tf_config = tf.ConfigProto(\n",
    "        allow_soft_placemerelunt=True,FC_output\n",
    "        log_device_placement=False)\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tf_config).as_default() as sess:\n",
    "        rnn = Song_Model()\n",
    "        # Summaries for loss and accuracy\n",
    "        tf.summary.scalar(\"loss\", rnn.loss)\n",
    "        tf.summary.scalar(\"accuracy\", rnn.accuracy)\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
